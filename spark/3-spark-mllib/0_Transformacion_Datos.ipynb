{"nbformat":4,"nbformat_minor":0,"metadata":{"anaconda-cloud":{},"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"z9eQZTS11hij"},"source":["# Transformaciones de Datos\n","\n","Usualmente no se tiene los datos en un formato conveniente. Una gran parte del trabajo con datos consiste en usar el conocimiento de un dominio determinado para saber cómo manejar los datos (eliminar algunos datos faltantes, realizar \"feature engineering\", transformar datos, etc.)\n","\n","Spark tiene métodos para realizar estas transformaciones: http://spark.apache.org/docs/latest/ml-features.html"]},{"cell_type":"code","source":["!pip install -q pyspark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DBrGGV8hSPl0","executionInfo":{"status":"ok","timestamp":1697523535183,"user_tz":300,"elapsed":31015,"user":{"displayName":"Oscar Efrain Ramos Ponce","userId":"06060603971885071383"}},"outputId":"a55fd8df-3767-46fe-e157-1546f58224c9"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","metadata":{"id":"oMRiZnWJ1hik","executionInfo":{"status":"ok","timestamp":1697523540886,"user_tz":300,"elapsed":5708,"user":{"displayName":"Oscar Efrain Ramos Ponce","userId":"06060603971885071383"}}},"source":["from pyspark.sql import SparkSession\n","spark = SparkSession.builder.getOrCreate()"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rPcpJ3RD1hiw"},"source":["## 1. Atributos categóricos a numéricos usando índices\n","\n","Se puede utilizar `StringIndexer` para convertir atributos categóricos (no numéricos) en atributos numéricos."]},{"cell_type":"code","metadata":{"id":"H6uu_9rh1hix","executionInfo":{"status":"ok","timestamp":1697523549634,"user_tz":300,"elapsed":438,"user":{"displayName":"Oscar Efrain Ramos Ponce","userId":"06060603971885071383"}}},"source":["from pyspark.ml.feature import StringIndexer"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["*Ejemplo*: creación manual de un dataframe donde el atributo \"sucursal\" es categórico (no es numérico)"],"metadata":{"id":"ZbARZfJWSdNN"}},{"cell_type":"code","metadata":{"id":"q-bzy7aZ2oa0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697527014886,"user_tz":300,"elapsed":10,"user":{"displayName":"Oscar Efrain Ramos Ponce","userId":"06060603971885071383"}},"outputId":"cb038962-b08f-458e-a443-09476160af62"},"source":["from pyspark.sql import Row\n","\n","df = spark.createDataFrame([Row(ID=0, sucursal=\"A\", venta=10000), Row(ID=1, sucursal=\"B\", venta=9000),\n","                            Row(ID=2, sucursal=\"C\", venta=15000), Row(ID=3, sucursal=\"A\", venta=14000),\n","                            Row(ID=4, sucursal=\"A\", venta=12000), Row(ID=5, sucursal=\"C\", venta=19000),\n","                            Row(ID=6, sucursal=\"D\", venta=11500), Row(ID=7, sucursal=\"D\", venta=5000)\n","])\n","df.show()"],"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+--------+-----+\n","| ID|sucursal|venta|\n","+---+--------+-----+\n","|  0|       A|10000|\n","|  1|       B| 9000|\n","|  2|       C|15000|\n","|  3|       A|14000|\n","|  4|       A|12000|\n","|  5|       C|19000|\n","|  6|       D|11500|\n","|  7|       D| 5000|\n","+---+--------+-----+\n","\n"]}]},{"cell_type":"markdown","source":["Se convertirá la columna \"sucursal\" en numérica utilizando `StringIndexer`. Primero se indica cuál es la columna de entrada (`inputCol`) y cuál será la columna de salida (`indiceSucursal`)"],"metadata":{"id":"zB9ApQ9dT2Gf"}},{"cell_type":"code","metadata":{"id":"utk-xKIw2znZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697527020413,"user_tz":300,"elapsed":7,"user":{"displayName":"Oscar Efrain Ramos Ponce","userId":"06060603971885071383"}},"outputId":"1f02a71c-227f-4fba-f29f-55a7ce1c0554"},"source":["# La columna con categoría indexada (numérica) se llamará \"indiceCategoria\"\n","indexador = StringIndexer(inputCol=\"sucursal\", outputCol=\"indiceSucursal\")\n","\n","# Obtener las asociaciones entre categorías y valore numéricos (mapa)\n","modeloIndexador = indexador.fit(df)\n","# Mostrar las etiquetas que se mapean como (0, 1, 2)\n","modeloIndexador.labels"],"execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['A', 'C', 'D', 'B']"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["modeloIndexador"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uIXAemFOWb31","executionInfo":{"status":"ok","timestamp":1697526273910,"user_tz":300,"elapsed":299,"user":{"displayName":"Oscar Efrain Ramos Ponce","userId":"06060603971885071383"}},"outputId":"7cc0fdf5-c5a2-425c-9a41-e273c5543970"},"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["StringIndexerModel: uid=StringIndexer_3f7500b4fb00, handleInvalid=error"]},"metadata":{},"execution_count":51}]},{"cell_type":"markdown","source":["Luego se transforma los datos según los índices generados. Notar que se utiliza `transform` para realizar esta transformación"],"metadata":{"id":"upQ0sdijUkLK"}},{"cell_type":"code","metadata":{"id":"2XiOKTx87boy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697527026473,"user_tz":300,"elapsed":702,"user":{"displayName":"Oscar Efrain Ramos Ponce","userId":"06060603971885071383"}},"outputId":"ba83c993-717d-4bbd-ff5d-9c4bd497f3d9"},"source":["# Transformar los datos según los índices generados\n","df2 = modeloIndexador.transform(df)\n","df2.show()"],"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+--------+-----+--------------+\n","| ID|sucursal|venta|indiceSucursal|\n","+---+--------+-----+--------------+\n","|  0|       A|10000|           0.0|\n","|  1|       B| 9000|           3.0|\n","|  2|       C|15000|           1.0|\n","|  3|       A|14000|           0.0|\n","|  4|       A|12000|           0.0|\n","|  5|       C|19000|           1.0|\n","|  6|       D|11500|           2.0|\n","|  7|       D| 5000|           2.0|\n","+---+--------+-----+--------------+\n","\n"]}]},{"cell_type":"markdown","source":["Luego de esta transformación, se puede utilizar el índice `indiceSucursal` como entrada numérica para algún algoritmo de Machine Learning."],"metadata":{"id":"Qg1dNpyBdIsH"}},{"cell_type":"markdown","source":["## 2. Atributos categóricos a numéricos usando One-hot Encoding"],"metadata":{"id":"SFDL-3K4VLzw"}},{"cell_type":"markdown","source":["La idea de one-hot encoding es mapear cada categoría a un vector binario con un solo valor que indique la presencia de un atributo particular (una característica específica)."],"metadata":{"id":"SpYm1K7udTo0"}},{"cell_type":"code","source":["from pyspark.ml.feature import StringIndexer, OneHotEncoder"],"metadata":{"id":"YKo8mZPBVl_J","executionInfo":{"status":"ok","timestamp":1697525159466,"user_tz":300,"elapsed":317,"user":{"displayName":"Oscar Efrain Ramos Ponce","userId":"06060603971885071383"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["# Data frame original\n","df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"53Zg6yTZVLdW","executionInfo":{"status":"ok","timestamp":1697527044391,"user_tz":300,"elapsed":654,"user":{"displayName":"Oscar Efrain Ramos Ponce","userId":"06060603971885071383"}},"outputId":"6ce83e35-dc8c-49b1-b433-010a41749829"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+--------+-----+\n","| ID|sucursal|venta|\n","+---+--------+-----+\n","|  0|       A|10000|\n","|  1|       B| 9000|\n","|  2|       C|15000|\n","|  3|       A|14000|\n","|  4|       A|12000|\n","|  5|       C|19000|\n","|  6|       D|11500|\n","|  7|       D| 5000|\n","+---+--------+-----+\n","\n"]}]},{"cell_type":"markdown","source":["**Forma 1**: Manipulando directamente el indexador y el conversor a one-hot encoding"],"metadata":{"id":"o5wl7Yi6aA4c"}},{"cell_type":"code","source":["# Crear y aplicar un indexador\n","indexador = StringIndexer(inputCol=\"sucursal\", outputCol=\"indiceSucursal\")\n","# Transformar y aplicar el indexador al DataFrame\n","df2 = indexador.fit(df).transform(df)\n","\n","# Definir One-Hot encoder\n","one_hot_encoder = OneHotEncoder(inputCol=\"indiceSucursal\", outputCol=\"onehotSucursal\")\n","# Transformar y aplicar OneHotEncoder al DataFrame\n","df3 = one_hot_encoder.fit(df2).transform(df2)\n","df3.show()"],"metadata":{"id":"Z7XFN5ppX_NC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697527080144,"user_tz":300,"elapsed":839,"user":{"displayName":"Oscar Efrain Ramos Ponce","userId":"06060603971885071383"}},"outputId":"0f13c4db-a8e9-4483-a177-20fab8d8a206"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+--------+-----+--------------+--------------+\n","| ID|sucursal|venta|indiceSucursal|onehotSucursal|\n","+---+--------+-----+--------------+--------------+\n","|  0|       A|10000|           0.0| (3,[0],[1.0])|\n","|  1|       B| 9000|           3.0|     (3,[],[])|\n","|  2|       C|15000|           1.0| (3,[1],[1.0])|\n","|  3|       A|14000|           0.0| (3,[0],[1.0])|\n","|  4|       A|12000|           0.0| (3,[0],[1.0])|\n","|  5|       C|19000|           1.0| (3,[1],[1.0])|\n","|  6|       D|11500|           2.0| (3,[2],[1.0])|\n","|  7|       D| 5000|           2.0| (3,[2],[1.0])|\n","+---+--------+-----+--------------+--------------+\n","\n"]}]},{"cell_type":"markdown","source":["**Forma 2**: Utilizando un pipeline"],"metadata":{"id":"5z69-Udraf-v"}},{"cell_type":"code","source":["from pyspark.ml import Pipeline"],"metadata":{"id":"tm5rojOmZjer","executionInfo":{"status":"ok","timestamp":1697525429878,"user_tz":300,"elapsed":5,"user":{"displayName":"Oscar Efrain Ramos Ponce","userId":"06060603971885071383"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["# Indexador sin aplicarlo al DataFrame\n","string_indexer = StringIndexer(inputCol=\"categoria\", outputCol=\"indiceCategoria\")\n","# OneHotEncoder sin aplicarlo al Dataframe\n","one_hot_encoder = OneHotEncoder(inputCol=\"indiceCategoria\", outputCol=\"onehotCategoria\")\n","\n","# Pipeline con las etapas\n","pipeline = Pipeline(stages=[string_indexer,\n","                            one_hot_encoder])\n","\n","# Obtener las asociaciones usando el pipeline\n","df2 = pipeline.fit(df)\n","\n","# Transformar el DataFrame\n","df3 = df2.transform(df)\n","\n","# Resultado\n","df3.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n7tOGd7QZejP","executionInfo":{"status":"ok","timestamp":1697526036314,"user_tz":300,"elapsed":962,"user":{"displayName":"Oscar Efrain Ramos Ponce","userId":"06060603971885071383"}},"outputId":"c3c5bf02-aa99-4f96-d87c-3d52b4b6d33b"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+---------+---------------+---------------+\n","| ID|categoria|indiceCategoria|onehotCategoria|\n","+---+---------+---------------+---------------+\n","|  0|        a|            0.0|  (2,[0],[1.0])|\n","|  1|        b|            2.0|      (2,[],[])|\n","|  2|        c|            1.0|  (2,[1],[1.0])|\n","|  3|        a|            0.0|  (2,[0],[1.0])|\n","|  4|        a|            0.0|  (2,[0],[1.0])|\n","|  5|        c|            1.0|  (2,[1],[1.0])|\n","+---+---------+---------------+---------------+\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"3M6idxnR1hi2"},"source":["## 3. Generación de un vector columna (combinando otras columnas)\n","\n","`VectorAssembler` combina un conjunto de columnas en un solo vector columna. Es útil para combinar atributos originales con aquellos generados por diferentes transformaciones aplicadas en PySpark. Esto es necesario para tener el formato que los modelos de ML de Spark utilizan.\n","\n","`VectorAssembler` acepta los siguientes tipos de columnas: todos los tipos numéricos, tipos Booleanos, tipos vector. En cada fila, los valores de las columnas de entrada serán concatenados en un vector de un orden especificado.\n","\n","Ejemplo: Si se tiene un DataFrame con las columnas id, campo1, campo2, campos3, y valor:\n","\n","     id | campo1 | campo2 |   campos3   | valor\n","    ----|--------|--------|-------------|------\n","    204 |   18   |   1.0  | [3, 10, 20] |  5.9\n","\n","donde `campos3` es una columna de vectores que contiene tres atributos. Se desea combinar `campo1`, `campo2` y `campos3` en un solo vector de atributos llamado `vatributos` para ser usado como predictor de `valor`. Si se indica que las columnas de entrada de `VectorAssembler` son `campo1`, `campo2` y `campos3`, y que la columna de salida es `valor`, luego de la transformación se obtendrá lo siguiente:\n","\n","     id | campo1 | campo2 |   campos3   | valor |     vatributos\n","    ----|--------|--------|-------------|-------|----------------------\n","    204 |   18   |   1.0  | [3, 10, 20] |  5.9  | [18, 1.0, 3, 10, 20]"]},{"cell_type":"code","metadata":{"id":"7Mo1k8uX-q7A"},"source":["from pyspark.ml.feature import VectorAssembler\n","from pyspark.ml.linalg import Vectors"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sAxnr-JX-scC"},"source":["# Vector denso en Spark\n","vector = Vectors.dense([3, 10, 20])\n","vector"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SYZqzQgP1hi2"},"source":["# Creación de un data frame (de una fila)\n","df = spark.createDataFrame([(204, 18, 1.0, vector, 5.9),\n","                            (205, 25, 3.5, vector, 6.7)],\n","                           [\"id\", \"campo1\", \"campo2\", \"campos3\", \"valor\"])\n","df.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cyrQyHyc1hi5"},"source":["# Objeto que juntará columnas para crear una sola columna\n","assembler = VectorAssembler(inputCols=[\"campo1\", \"campo2\", \"campos3\"],\n","                            outputCol=\"vatributos\")\n","\n","# Transformar los datos según la columna creada\n","df2 = assembler.transform(df)\n","df2.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Az8pxJGTAtkn"},"source":["df2.show(truncate=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jlNFZIxL1hi7"},"source":["# Seleccionar solo las columnas vatributos y valor (usual como entrada a algoritmos supervizados)\n","df2.select(\"vatributos\", \"valor\").show()"],"execution_count":null,"outputs":[]}]}